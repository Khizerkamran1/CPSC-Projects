# -*- coding: utf-8 -*-
"""DATA 607 Final Project Report.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17_8iqVcYOCe2qcnpGpcw0IFPQ3-YddsD

Course: DATA 607 L01

Professor: Qingrun Zhang

Teaching Assistants (TA): Archibald Qian, Hamid Hamidi

<br>

Khizer Kamran

#Introduction:

Canadian Wind Turbine Database:

The Canadian Wind Turbine Database contains the geographic location and key technology details for wind turbines installed in Canada. This database consists of 15 columns and 6,698 rows of which all describe recorded information regarding the types of turbines installed within various geographical locations in Canada alongside also describing the power that these various types of turbines generate (in kW).

The columns can be described as follows:

1. ‘Object ID’ is a key used to identify each turbine allocated
2. ‘Province/Territory’ are the geographical locations in which the turbine was installed
3. ‘Project Name’ are the group(s) of turbines installed collectively within a geographical area
4. ‘Total Project Capacity (in MW)’ is the total power generated by a collection of turbines
5. ‘Turbine Identifier’ are the IDs for identifying individual turbine types
6. ‘Turbine Number are the number of turbines in 1 project collection
7. ‘Turbine Rated Capacity (in kW)’ is the amount of power generated by 1 turbine type
8. ‘Rotor Diameter (in m)’ is the length of the rotor used within 1 particular type of turbine
9. ‘Turbine Hub (in m)’ is the length of the hub connected to 1 particular type of turbine
10. ‘Manufacturer’ is the company that manufactured the turbine
11. ‘Model Type’ is the model version of the turbines being used
12. ‘Commission Date’ is when the turbines were installed
13. ‘Latitude’ is the latitude coordinates of where the turbine is located geographically
14. ‘Longitude’ is the longitude coordinates of where the turbine is located geographically
15. ‘Notes’ contain any additional information associated with the turbine.

Guiding Questions:
1.	What factors should be included when analyzing the optimization of turbine power generation (which columns or attributes should be included or excluded)?
2.	What models can work to help illustrate the generation of power through its various class types (which models discussed from in-class discussions can help us to determine accurately the generation of power from turbines)?
3.	Which of our chosen models proved to meet our goals (which model is the best, with the best optimization parameters)?
4. What role does classification play in predicting the manufacturing labels of the highest power generating turbines?
5.	What conclusions can we draw from our models and how do we go about applying this within the real world (what can we do with our insights)?
6.	What are some potential challenges or limitations when using machine learning models to optimize turbine power generation, and how can we address them?

Proposed Methodology:


  Our proposed methodology will contain the following machine learning methods, which will allow us to balance optimality with high efficiency and accuracy when predicting the best model to fit our data as well as predict classes:
1. Linear Regression / Polynomial Regression / KNN Classification / SVM Modelling (to help predict the total project capacity optimally)
2. LDA (for factor reduction)
3. KNN / Gaussian Naïve Bayes / Multinomial Classifications (to maximize our accuracy with classification modelling)
4. Decision Tree Analysis (alternative approaches to modeling our dataset for alternative optimality levels)
5. Neural Network Class-label Classification

From this information we will now re-highlight the overall purpose or overarching problem statements of our analysis:

*What highly accurate (or optimal) model can help us to best predict the total capacity associated with each of the dataset's major projects*

*What highly accurate (or optimal) model can help us to best classify the manufacturers of the highest performing (or most high power generating) turbines?*

*Note: We have run our cells multiple times over to test if our code worked synergistically as such all testing accuracies and numerical outputs are in close approximation to our original run of the code.*

Importing all necessary libraries for our analysis.
"""

import pandas as pd
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import math
from patsy import dmatrices
import statsmodels.discrete.discrete_model as sm
import statsmodels.formula.api as smf
import statsmodels.api as sma
from statsmodels.graphics.regressionplots import *
from sklearn import datasets, linear_model
from sklearn.metrics import confusion_matrix
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA
from sklearn.naive_bayes import GaussianNB as NB
from sklearn.neighbors import KNeighborsClassifier as KNN
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn import tree
import pandas as pd
import numpy as np
import os
import shutil
import pickle as pk
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from keras import models
from keras import layers
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.models import load_model

"""#Part I: Regression Modelling For Turbine Dataset

We will begin the regression portion of our analysis by loading our dataset and converting the 'turbineCapacity' column to numerical values whilst also dropping non-numerical values from the columns.
"""

data = pd.read_csv('Turbine.csv')
data = data[['Turbine rated capacity (kW)', 'Rotor diameter (m)', 'Hub height (m)','Total project capacity (MW)']]
data  = data.rename(columns={'Turbine rated capacity (kW)':'turbineCapacity', 'Rotor diameter (m)':'rotorDiametre','Hub height (m)':'hubHeight', 'Total project capacity (MW)':'projectCapacity'})

data['turbineCapacity'] = pd.to_numeric(data['turbineCapacity'], errors='coerce')
data = data.dropna()
data['turbineCapacity'] = data['turbineCapacity'].astype(float)
data

"""Through feature selection for our regression modelling process we determined that the turbines total capacity (on an individual level), the diameter of the rotor, and the height of the hub were the best independent variables to use when predicting the total project capacity."""

X = data[['turbineCapacity', 'rotorDiametre', 'hubHeight']]
y = data['projectCapacity']

x_train,x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

"""We will now fit the training set to the linear regression model and calculate the RMSE value."""

linear = LinearRegression()
linear.fit(x_train, y_train)
y_pred = linear.predict(x_test)

accuracy = linear.score(x_test, y_test)
print("Testing Accuracy: ", accuracy)

print('Coefficient: \n', linear.coef_)
print('Intercept: \n', linear.intercept_)

rmse = mean_squared_error(y_test, y_pred, squared=False)

print('RMSE: ', rmse)

"""In this code, we have trained a linear regression model to predict the project capacity based on the turbine capacity, rotor diameter, and hub height. We first split the data into training and testing sets and then fit the linear regression model on the training set. After that, we made predictions on the test set and calculated the accuracy score of the model, which turned out to be 0.54. Next, we printed the coefficients and intercept of the linear regression model to understand the effect of each feature on the project capacity. The coefficients were [ 0.00230919, -0.00524542, 1.72080058] for turbine capacity, rotor diameter, and hub height respectively, indicating that hub height has the strongest positive effect on project capacity, followed by turbine capacity with a small positive effect, while rotor diameter has a negative effect. Finally, we calculated the root mean squared error (RMSE) for both the training and testing sets, which was 83.68. The RMSE represents the average difference between the actual and predicted project capacity, with lower values indicating a better fit of the model. Overall, the linear regression model provided some insights into the relationship between the input features and the project capacity, but there may be other variables that could have an impact on the outcome.

We will now repeat the process for our polynomial regression modelling process.
"""

model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())
model.fit(x_train, y_train)
y_train_pred = model.predict(x_train)
y_test_pred = model.predict(x_test)

train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f"Train R-squared score: {train_r2:.2f}")
print(f"Test R-squared score: {test_r2:.2f}")

"""We will also plot the actual vs. the predicted values to evaluate the validity of the polynomial regression model."""

plt.scatter(y_test, y_test_pred)
plt.plot([0, 250], [0, 250], color='red')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted')
plt.show()

"""Using the data thus far, we can also apply the KNN classifier to our current modelling process to help discover a more optimal model for predicting the total project capacity. We will start by discretizing the total project capcity column into three separate categories, and from there we will split the data similarly in our earlier process. From here we will use a for-loop to help predict the class-labels of the test set and report the accuracy score. We have also provided a plot for easier evaluation of the model's testing accuracy."""

data['projectCapacity'] = pd.cut(data['projectCapacity'], bins=[0, 50, 100, float('inf')], labels=['low', 'medium', 'high'])

data.dropna(inplace=True)

X = data[['turbineCapacity', 'rotorDiametre', 'hubHeight']]
y = data['projectCapacity']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

k_range = range(1, 11)

accuracy_scores = []

for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)

    y_pred = knn.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    accuracy_scores.append(accuracy)

best_k = k_range[accuracy_scores.index(max(accuracy_scores))]
print(f"Best accuracy score = {max(accuracy_scores)} for k = {best_k}")

plt.plot(k_range, accuracy_scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Accuracy')
plt.title('Accuracy Scores for Different Values of K')
plt.show()

"""Lastly to optimize our regression models we have used the SVC approach (which will help to find which model is the most accurate for the regression component of our model selection process).

Here we will create the SVM model using a kernal 'rbf' then train our model similarly to our prior process and from there make predictions on the test data set whilst simultaneously gathering accuracy scores upon the test set. We will also print out a classification report to help support the validity of our model.
"""

svm_model = SVC(kernel='rbf')

svm_model.fit(x_train, y_train)

y_train_pred = svm_model.predict(X_train)
y_test_pred = svm_model.predict(X_test)

train_acc = accuracy_score(y_train, y_train_pred)
test_acc = accuracy_score(y_test, y_test_pred)

print(classification_report(y_test, y_test_pred))

print("Training accuracy:", train_acc)
print("Testing accuracy:", test_acc)
print('\n')

"""Based on the models used, the K Nearest Neighbor Classifier was found to be the most effective in predicting power generation through its categorized bins, such as low, medium, and high. When the power generation variable was divided into these bins, the KNN classifier achieved an accuracy rate of 85%. In contrast, Linear Regression resulted in an accuracy rate of only 8%, and the Polynomial Regression explained only 13% of the variance in the target variable. Therefore, the KNN classifier outperformed both Linear and Polynomial Regression models in predicting the power generation.

The final selections for regression modelling:

1. KNN Classifier - 85%
2. SVM - 54%
3. Polynomial Regression - 13%
4. Linear Regression - 8%

#Part II: Linear Discriminant Analysis

The main goal of this section is to help us to aim our focus towards only those specific variables or factors that are most important when contributing to our dataset. The aim of this section is to help us to reduce the number of independent variables that we will include in our dataset moving forward. We would also like to focalize our goal within this section so that we may have more specific algorithms for our problem statement.

We first begin by loading the necessary libraries needed to load the turbine dataset. We will also load the data and drop the 'Notes' column (as this column contains NA values and won't be useful to us moving forward). Similarly, we are eliminating the 'OBJECTID' column as we will be using another method for indexing.
For columns: 'Latitude', 'Longitude', 'Province/Territory', 'Project name'; we will come back to these variables when remarking on our analysis at the very end.
"""

df = pd.read_csv("Turbine.csv")
df = df.drop("Notes", axis=1)
df = df.drop("OBJECTID", axis=1)
df = df.drop("Latitude", axis=1)
df = df.drop("Longitude", axis=1)
df = df.drop("Province/Territory", axis=1)
df = df.drop("Project name", axis=1)
df

"""We will now begin with our first method of factor reduction which is by using the 'Linear Discriminant Analysis (LDA)' method. The LDA method allows us to look at our dataset from a hollistic approach and fundamentally reduce our dataset to only those specific factors that influence the classifications (and likewise predictions) found from the inevitable analysis of our turbine data.

The first step in the LDA process requires us to manipulate 2 of of our main categorical variables by combining both variables into one, more specific set of class; for our purposes here we will be transforming the data from string to categorical identifiers.

The columns that will need to be changed are as follows:

(1) Turbine Identifier

(2) Model
"""

df['TurbineModel'] = df['Turbine identifier'] + df['Model']

"""Now we can begin with splitting our dataset into training and test sets for the LDA process. Here we will be using the 'Commission date' column to help us grab information based on year and split according to a date filter that we will now create. Simultaneously we will also be removing inter-year commissioning date data as this allows us to have more concise years to work with when splitting our for further exploration."""

df = df.drop(df[df['Commissioning date'] == '2000/2001'].index)
df = df.drop(df[df['Commissioning date'] == '2006/2007'].index)
df = df.drop(df[df['Commissioning date'] == '2005/2006/2012'].index)
df = df.drop(df[df['Commissioning date'] == '2004/2005'].index)
df = df.drop(df[df['Commissioning date'] == '2002/2006'].index)
df = df.drop(df[df['Commissioning date'] == '2006/2008'].index)
df = df.drop(df[df['Commissioning date'] == '2004/2005'].index)
df = df.drop(df[df['Commissioning date'] == '2011/2012'].index)
df = df.drop(df[df['Commissioning date'] == '2013/2014'].index)
df = df.drop(df[df['Commissioning date'] == '2014/2015'].index)
df = df.drop(df[df['Commissioning date'] == '2001/2003'].index)
df = df.drop(df[df['Commissioning date'] == '2001/2003'].index)
df = df.drop(df[df['Turbine rated capacity (kW)'] == '1815/1950'].index)
df = df.drop(df[df['Turbine rated capacity (kW)'] == '1903/2126/2221'].index)
df = df.drop(df[df['Turbine rated capacity (kW)'] == '1800-2300'].index)
df

"""For our convenience moving further we will now rename our columns and drop the columns that were used to created the new, combined column."""

df = df.rename(columns={'Province/Territory':'PT', 'Project name':'PN', 'Total project capacity (MW)': 'TPC', 'Turbine number in project': 'TNP', 'Turbine rated capacity (kW)': 'TRC', 'Rotor diameter (m)': 'RD', 'Hub height (m)': 'HH', 'Manufacturer': 'MU', 'Model': 'MO', 'Commissioning date': 'CD', 'Latitude': "LA", "Longitude":"LO", "Turbine identifier": "TI"})
df[["TNPN", "TNPD"]] = df["TNP"].str.split("/", expand=True)
df = df.drop('TNP', axis=1)
df = df.drop('TI', axis=1)
df = df.drop('MO', axis=1)
df['MU2'] = pd.factorize(df['MU'])[0]
df

"""We will now split the dataset into training and test sets by using the year 2006 as a main condition for filtering. 2006 is halfway between 1993 and 2019 (the start and end years of our data) and thus we felt that this filtering would best allow us to split the data in such a way that our models would be capturing the past (more historical data) more accurately when making predictions on more contempory data."""

X = df[['TPC', 'TRC', 'RD', 'HH']]
y = df['MU']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Linear Discriminant Analysis (LDA)

We will first start by creating an LDA object, then from there we will create our projection matrix, we will use this model to project X which will then give us the predicted label for each sample and likewise the probabilities of each sample belonging to each class. This is specifically for the training process.
"""

model = LDA()
model.fit(X_train, y_train)

"""From here we will now use a repeated stratified k-fold method to help provide a way to improve the estimated performance of our machine learning model. This involves simply repeating the cross-validation procedure (as many times as we need to) multiple times and reporting the mean result across all folds from all runs. We will also print out the accuracy of the current LDA model."""

cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)

scores_te = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1)
print(np.mean(scores_te))

"""Likewise it is important to also graph the model and the respective information we have collected thus far to help support the testing accuracy."""

X = df[['TPC', 'TRC', 'RD', 'HH']]
y = df['MU']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

sc = StandardScaler()
X = sc.fit_transform(X)

lda = LDA(n_components=2)
lda_object = lda.fit(X, y)
X = lda_object.transform(X)

plt.figure(facecolor='violet')
ax = plt.axes()
ax.set_facecolor("pink")

for l,c,m in zip(np.unique(y),['red', 'blue', 'green', 'yellow', 'black', 'purple', 'grey', 'pink',
                               'purple', 'violet', 'orange', 'brown', 'cyan', 'magenta', 'fuchsia', 'darkmagenta',
                               'lime', 'tan', 'sienna', 'coral', 'yellowgreen', 'chocolate', 'deeppink', 'crimson'],
                 ['o','o','o','o','o','o','o','o',
                  'o','o','o','o','o','o','o','o',
                  'o','o','o','o','o','o','o']):
    plt.scatter(X[y==l,0],
                X[y==l,1],
                c=c, marker=m, label=l,edgecolors='black')
    plt.legend(bbox_to_anchor=(1.0, 1.0), borderpad=2)
    plt.title("LDA Scatterplot")
    plt.xlabel("Featured Columns")
    plt.ylabel("Class Labels")

"""Conclusions:

The accuracy of 52.02% can be interpreted as the value that is associated with this current model that can accurately predit the test set. More simply put, currently our model is 52.90% accurate when predicting the values or data of the test set.

The accuracy here initially is 52.02%, although this is not the most optimal model for our algorithmic approach we can see that by utilizing these variables alongside further optimality models we will be able to greatly increase this accuracy level to its highest.

The linear Discriminant analysis estimates the probability that a new set of inputs belongs to every class within our dataset. The output class is the one that has the highest probability. That is how the LDA makes its prediction. However, as we can evaluate from our plot, it is increasingly more difficult to make a decision based on the graph. Another model will be needed to help us with the decision-making process of our analysis (A.K.A Decision Tree analysis will be needed). We can, however, surmise that the manufacturer 'Enercon' is quite common amongst a majority of the turbine projects. This indicates that the projects that have relied on Enercon's turbines have provided enough value to the projects total capacity rating for it to be re-used multiple times over.

In this section we determined that our most important variables are as follows:

1) Indepedent Variables: 'Total Project Capacity (MW)', 'Total Rated Capacity (kW)', 'Rotor Diameter (m)', and 'Hub Height (m)'

2) Dependent Variables: 'Manufacturer'

Moving forward from sections II to IV we will be using these independent and dependent variables for our feature selections.

#Part III: Classification Modeling

The main goal of this second section is to help us to aim our focus towards only those optimal models that are most important when contributing to modelling our dataset. The aim of this section is to help us to reduce the number of models that can aid us in fitting our dataset with its respective classes, and in the process, to help us reach the highest level of accuracy possible within our model selection process.

K-Nearest Neighbour Classification

We begin by using the KNN classification method. From section I we continue to create splits based off of our featured selection and labels.
"""

X = df[['TPC', 'TRC', 'RD', 'HH']]
y = df['MU']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""We then apply the KNN classifier to the training dataset"""

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)

"""We then predict our test set."""

y_pred = knn.predict(X_test)

"""Then we calculate the test accuracy for our dataset using the KNN classifier."""

accuracy = accuracy_score(y_test, y_pred)
print("Testing Accuracy:", accuracy)

"""Gaussian Naive Bayes Classification

We weill now be using the Gaussian Naived Bayes classification method. From section I we continue to create splits based off of our featured selection and labels.
"""

X = df[['TPC', 'TRC', 'RD', 'HH']]
y = df['MU']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""We will now use the Gaussian Naive Bayes model and fit it to our training set."""

nb = GaussianNB()
nb.fit(X_train, y_train)

"""Likewise, we will also print out the predicted values."""

y_pred = nb.predict(X_test)

"""We will also calculate the testing set's accuracy once again."""

accuracy = accuracy_score(y_test, y_pred)
print("Testing Accuracy:", accuracy)

"""Multi-nomial Classification

Lastly, we will repeat the process once more for our Multi-nomial Classification model. Beginning with the same train/test split as before.
"""

X = df[['TPC', 'TRC', 'RD', 'HH']]
y = df['MU']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""We will now apply the Multi-nomial Naive Bayes model to our dataset."""

me = MultinomialNB()
me.fit(X_train, y_train)

"""Once more, we will get the 'y' predicted values from our model."""

y_pred = me.predict(X_test)

"""Lastly, we will print out the testing accuracy scores for the Mult-nomial Classification model."""

print("Testing Accuracy: ", accuracy_score(y_test, y_pred))

"""Conclusions:

From this section when we evaluate each of our models we are aiming to discover the highest level of accuracy when predicting the classification labels of our turbine datasets manufacturers' class.

The models are order below (from highest to lowest accuracy - thus far):

1. KNN Model - 99.01%
2. Gaussian Naive Bayes - 59.36%
3. Linear Discriminant Analysis - 52.02%
4. Multi-nomial Model - 29.68%


We find from our analysis thus far that the highest accuracy is achieved from our KNN model, with a descrepancy of 40-60% when compare to the other 3 remaining models. KNN is most useful in this case because the labeled data is too expensive or impossible to obtain, and it can achieve high accuracy in a wide variety of prediction-type problems associated with the turbines' information. KNN is a simple algorithm, based on the local minimum of the target function which is used to learn an unknown function of desired precision and accuracy of our turbine labels.

It should be mentioned that models such as the Multi-nomial based fitting would not work well with this particular dataset because the multinomial naïve Bayes is more commonly used for assigning documents or records to classes based on the statistical analysis of their contents. It provides an alternative to the "heavy" AI-based analysis and drastically simplifies 'TEXTUAL' data classification (thus not particularly powerful or useful with other forms of data classifications).

#Part IV: Decision Tree Analysis

Decision Tree Classification

The main goal of this third section is to help us to aim our focus towards helping us to focalize our efforts towards models that balance optimal accuracy with decision-making ability. The aim of this section is to once again help us to reduce the number of models that can aid us in fitting our dataset with its respective classes, and in the process, to help us reach the highest level of accuracy possible within our model selection process.

We once again begin by splitting our data as we had done in prior sections.
"""

feature_cols = ['TPC', 'TRC', 'RD', 'HH']
cn = df['MU']

X = df[['TPC', 'TRC', 'RD', 'HH']]
y = df['MU']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""We then apply our Decision Tree Classification model to fit to our training data."""

clf = DecisionTreeClassifier()

clf = clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)

"""We will also pring out the testing set's accuracy."""

print("Testing Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""From here we will create the decision tree map and analyze which pathway is most effective when selecting manufacturers for turbine designs within component selection for projects."""

fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (15,15), dpi=700)

tree.plot_tree(clf,
               feature_names = feature_cols,
               class_names=cn,
               filled = True)

fig.savefig('imagename.png')

"""Conclusions:

From this section when we evaluate each of our models we are aiming to discover the highest level of accuracy when predicting the classification labels of our turbine datasets manufacturers' class.

The models are order below (from highest to lowest accuracy - thus far):

1. Decision Tree Model - 99.73%
2. KNN Model - 99.01%
2. Gaussian Naive Bayes - 59.36%
3. Linear Discriminant Analysis - 52.02%
4. Multi-nomial Model - 29.68%

From our decision tree classification diagram and model we have concluded that the 3 main major manufacturers who have contributed the most to the total capacity and power generated output of the total collection of projects are as follows:

1. Enercon
2. Nordex
3. Vestas

Taken altogether our analysis has indicated that the decision-tree classification model is the most optimal and accurate model when predicting class labels for the turbines' manufacturers.

#Part V: Alternative Approach to Model Accuracy - Neural Network Class-Label Classification

We would like to conclude our analysis with an alternative approach to model creation (outside of our main models and the most optimal model selected prior). This approach requires the use of model sequentially created layers that will help us to iterate through and check the losses of accuracy through each epoch of our iteration (concluding with a final model and accuracy level). Although we have already concluded that the decision tree classifier is the most optimal model for our data we wanted to expand our analysis to this alternative strategy (though it may prove less accurate). This portion of the analysis will also look at the concept of overfitting and how this plays a major role when predicting the dataset's class labels.

We will split the data as common with prior sections and we will also reshape as well as transform the labels' data.
"""

X = df[['TPC', 'TRC', 'RD', 'HH']].astype('float')
y = df['MU']

encoder = OneHotEncoder()

encoded_Y = encoder.fit(y.values.reshape(-1,1))
encoded_Y = encoded_Y.transform(y.values.reshape(-1,1)).toarray()

encoded_Y

"""We will now create various splits for training, testing, and validation sets whilst simultaneously creating these splits."""

train_ratio = 0.70
validation_ratio = 0.15
test_ratio = 0.15

trainX, testX, trainY, testY = train_test_split(X, encoded_Y, test_size= 1 - train_ratio)
valX, testX, valY, testY = train_test_split(testX, testY, test_size=test_ratio/(test_ratio + validation_ratio))

"""We want to find the unique counts of all of our class labels."""

y_part = [trainY, valY, testY]

for y_part in y_part:
    re_transformed_array = encoder.inverse_transform(y_part)

    unique_elements, counts_elements = np.unique(re_transformed_array, return_counts=True)
    unique_elements_and_counts = pd.DataFrame(np.asarray((unique_elements, counts_elements)).T)
    unique_elements_and_counts.columns = ['unique_elements', 'count']
    print('---------------')
    print(unique_elements_and_counts)

"""We are now going to be creating vectors to help configure our neural network model creation process."""

checkpoint_no = 'ckpt_1_ANN'
model_name = 'Bird_ANN_2FC_F64_64_epoch_25'

input_shape = trainX.shape[1]

n_batch_size = 20

n_steps_per_epoch = int(trainX.shape[0] / n_batch_size)
n_validation_steps = int(valX.shape[0] / n_batch_size)
n_test_steps = int(testX.shape[0] / n_batch_size)

n_epochs = 25

num_classes = trainY.shape[1]

print('Input Shape: ' + str(input_shape))
print('Batch Size: ' + str(n_batch_size))
print()
print('Steps per Epoch: ' + str(n_steps_per_epoch))
print()
print('Validation Steps: ' + str(n_validation_steps))
print('Test Steps: ' + str(n_test_steps))
print()
print('Number of Epochs: ' + str(n_epochs))
print()
print('Number of Classes: ' + str(num_classes))

"""We will now create the model using our configured settings."""

model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(input_shape,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(num_classes, activation='softmax'))

"""We will also print out the information associated with the layers, output shapes, and unique parameters associated with our data."""

model.summary()

"""We will now compile the model using categorical analysis and accuracy training metrics."""

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

"""We will also create a checkpoint directory for our model and analysis moving forward."""

checkpoint_dir = './'+ checkpoint_no
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)

"""We will create a vector that will contain the model checkpoint analysis output and store it in the checkpoint directory."""

keras_callbacks = [ModelCheckpoint(filepath = checkpoint_dir + '/' + model_name,
                                   monitor='val_loss', save_best_only=True, mode='auto')]

"""We will now fit our model with all configuration settings inplace."""

history = model.fit(trainX,
                    trainY,
                    steps_per_epoch=n_steps_per_epoch,
                    epochs=n_epochs,
                    batch_size=n_batch_size,
                    validation_data=(valX, valY),
                    validation_steps=n_validation_steps,
                    callbacks=[keras_callbacks])

"""Print out a dataframe containing all of the accuracies and losses."""

hist_df = pd.DataFrame(history.history)
hist_df['epoch'] = hist_df.index + 1
cols = list(hist_df.columns)
cols = [cols[-1]] + cols[:-1]
hist_df = hist_df[cols]
hist_df.to_csv(checkpoint_no + '/' + 'history_df_' + model_name + '.csv')
hist_df.head()

"""Find the highest accuracy."""

values_of_best_model = hist_df[hist_df.val_loss == hist_df.val_loss.min()]
values_of_best_model

"""Find the class-label assignment for the highest accuracy."""

class_assignment = dict(zip(y, encoded_Y))

df_temp = pd.DataFrame([class_assignment], columns=class_assignment.keys())
df_temp = df_temp.stack()
df_temp = pd.DataFrame(df_temp).reset_index().drop(['level_0'], axis=1)
df_temp.columns = ['Category', 'Allocated Number']

df_temp.to_csv(checkpoint_no + '/' + 'class_assignment_df_' + model_name + '.csv')

print('Class assignment:')
class_assignment

"""Plot the accuracies and class-label assignments."""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

"""In the following cells we will be re-loading our best model, then we will test our model using test data and then we will be reporting the testing accuracy alongside the predicted 'y' values."""

model_reloaded = load_model(checkpoint_no + '/' + model_name)

root_directory = os.getcwd()
checkpoint_dir = os.path.join(root_directory, checkpoint_no)
model_name_temp = os.path.join(checkpoint_dir, model_name + '.h5')
model_reloaded.save(model_name_temp)

folder_name_temp = os.path.join(checkpoint_dir, model_name)
shutil.rmtree(folder_name_temp, ignore_errors=True)

best_model = load_model(model_name_temp)

test_loss, test_acc = best_model.evaluate(testX,
                                          testY,
                                          steps=n_test_steps)
print()
print('Test Accuracy:', test_acc)

y_pred = model.predict(testX)
y_pred[:5]

"""From this section when we evaluate each of our models we are aiming to discover the highest level of accuracy when predicting the classification labels of our turbine datasets manufacturers' class.

The models for classification of manufacturing labels are ordered below (from highest to lowest accuracy - thus far):

1. Decision Tree Model - 99.73%
2. KNN Model - 99.01%
3. Gaussian Naive Bayes - 59.36%
4. Neural Network Model - 58.31
5. Linear Discriminant Analysis - 52.02%
6. Multi-nomial Model - 29.68%

Prevention of Overfitting the Model:

At this point we would like to remind you of the topic of overfitting and how to reduce such aspects from our model training process (specifically for neural networks):

1. Reduce the network’s size
2. Adding weight regularization
3. Adding dropout

The specific problem with overfitting is that our models become more biased and specific when training our data. Overfitting would occur most evidently with our decision tree model as it cannot generalize the dataset and fits too closely to the training dataset instead. Overfitting happens due to several reasons, such as: the training data size is too small and does not contain enough data samples to accurately represent all possible input data values.

#Concluding Statement and Real World Overview

The power generation of wind turbines depends on different factors including average annual wind speed, pre-twist, pitch, angle of attach, rotor swept area, and air density. Climate factors such as wind speed, turbine swept area, air density, site temperature, and tower height must be considered when designing a wind turbine for a particular site (El-Ahmar, M. H., et al.). Taller wind turbines generate more power as wind speeds are typically higher at greater heights. The use of a wind direction sensor and a motorized yaw system can increase power output by orienting the blades to face the wind.

The purpose of this study was to analyze the optimization of wind turbine power generation in Canada, using the Canadian Wind Turbine Database. The study focused on identifying the factors that should be included in analyzing the optimization of turbine power generation, to help us determine the models that can accurately illustrate the generation of power through various class types, and by optimizing these models, we were able to increase the accuracy of our predictions, as well as select the best model with the best optimization parameters.

In this study we have used various machine learning methods such as LDA/QDA, Regression, KNN Classification, SVM, Cross Validation, Grid Search Optimization, and Gaussian Bayes/Naïve Bayes/Multinomial Classifications. The purpose of this study was to provide insights into optimizing wind turbine power generation and potentially into improving the efficiency and effectiveness of wind energy production in Canada.

The process of power generation from wind turbines is complex and involves multiple interacting variables, including wind speed, blade pitch, and rotor speed. Capturing the complex system dynamics in a machine learning model can be difficult, and inaccurate or incomplete models can lead to suboptimal performance.

There are various challenges and limitations when using machine learning models to optimize turbine power generation. These challenges include the lack of complete data, the difficulty in accurately modeling complex systems, and the need for accurate and timely data.

To address these challenges, researchers may need to explore different data sources and employ advanced modeling techniques, such as deep learning or ensemble models. It is also important to develop new methods for data collection and validation, and to continually refine and improve models as new data becomes available. Additionally, collaboration between different stakeholders, such as researchers, industry experts, and policymakers, may be necessary to address these challenges and develop effective solutions.

Incase of this dataset we can see that there are limited number of features in the dataset. The dataset do not contain all the relevant variables that affect turbine power generation, such as wind speed, wind direction, and air density. To address this limitation, additional data sources may need to be integrated, or more advanced feature engineering techniques may need to be employed.

Machine learning models such as neural networks, decision trees or support vector machines can be used to address  the modeling of complex and nonlinear relationships between the features and the target variable.

It is important to continuously evaluate the performance of the machine learning models and adjust it accordingly. This can be done by monitoring the accuracy, precision, and recall of the model and fine-tuning it as necessary.

#Bibliography (APA 6th Edition)

Michael Fuchs Python. (Michael Fuchs, 2021). NN – Artificial Neural Network for Multi-Class Classfication. Retrieved
https://michael-fuchs-python.netlify.app/2021/02/23/nn-artificial-neural-network-for-multi-class-classfication/#loading-the-libraries

Open Canada. (Government of Canada, 2020). Canadian Wind Turbine Dataset. Retrieved
from https://open.canada.ca/data/en/dataset/79fdad93-9025-49ad-ba16-c26d718cc070

University of Calgary. (Qingrun Zhang, 2023). DATA 607 Lecture Notes. Retrieved
https://d2l.ucalgary.ca/d2l/le/content/500636/Home
"""
